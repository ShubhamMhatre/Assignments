{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parkinsonâ€™s Disease (PD) is a degenerative neurological disorder marked by decreased dopamine levels in the brain. In the below dataframe, Status is your target variable. 1 denoting Parkinson Positive and 0 denoting Parkinson negative. Jitter and schimmer are two important features to predict the presence of Parkinson. Read the data decription given below to get an idea about the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Attribute Information:\n",
    "\n",
    "#Matrix column entries (attributes):\n",
    "#name - ASCII subject name and recording number\n",
    "#MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "#MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "#MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "#MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several \n",
    "#measures of variation in fundamental frequency\n",
    "#MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "#NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "#status - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "#RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "#DFA - Signal fractal scaling exponent\n",
    "#spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Load the dataset (1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 The column 'name' is acting as an ID. No need to include it in dataframe. Remove thic column permanently from the dataframe. (2m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Print number of rows and columns. (1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Use the .describe() method on the dataset and state any insights you may come across. (1m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Plot the countplot for the target variable. Write interpretations. (2m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Check for missing vaues and take necessary measures by dropping observation or imputing them. (2m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Plot the distribution of all the features. State any observations you can make about the skewness based on the distribution plots. (3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 Are there any strong correlations among the independent features? Check with the help of heatmap and write conclusions. (3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.9 Separate your X and Y. Here status is your dependent variable. (2m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.10 Use Min - Max scaling to scale your features. Store this in a dataframe say dfscaled.  This scaled data is to be used for KNN algorithm. (3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting, model fitting and model evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Split dataset into training & test dataset . Take test_size = 0.2 (2m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Fit the KNN algorithm. Use different values of k ranging from k = 1,3,5,...,15. Find which value of K gives the best accuracy or least error. i.e. find optimal k using error rate graph. (8m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Fit the KNN algorithm again, using optimal value of K. Make predictions on test data and find accuracy,recall for the test data. (3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Extract the two columns given below from the scaled data and store them in x for clustering purpose  : \n",
    "#### 1) 'MDVP:Jitter(%)'    2)  'MDVP:Shimmer'  (3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now fit the Kmeans++ algorithm over this x data. Try values of K ranging from 1 to 10. Plot the graph of K vs WCSS and decide the optimal number of clusters from the graph. (8m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Fit the Kmeans++ again, using optimal k over x dataframe. Assign clusterlabels to the dataframe. Visualize the clusters and centroids. You can write conclusion from the clusters graph. (6m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
